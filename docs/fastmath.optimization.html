<!DOCTYPE html PUBLIC ""
    "">
<html><head><meta charset="UTF-8" /><title>fastmath.optimization documentation</title><script type="text/javascript" async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script><link rel="stylesheet" type="text/css" href="css/default.css" /><link rel="stylesheet" type="text/css" href="highlight/solarized-light.css" /><script type="text/javascript" src="highlight/highlight.min.js"></script><script type="text/javascript" src="js/jquery.min.js"></script><script type="text/javascript" src="js/page_effects.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body><div id="header"><h2>Generated by <a href="https://github.com/weavejester/codox">Codox</a> with <a href="https://github.com/xsc/codox-theme-rdash">RDash UI</a> theme</h2><h1><a href="index.html"><span class="project-title"><span class="project-name">Fastmath</span> <span class="project-version">2.0.0-SNAPSHOT</span></span></a></h1></div><div class="sidebar primary"><h3 class="no-link"><span class="inner">Project</span></h3><ul class="index-link"><li class="depth-1"><a href="index.html"><div class="inner">Index</div></a></li></ul><h3 class="no-link"><span class="inner">Namespaces</span></h3><ul><li class="depth-1"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>fastmath</span></div></div></li><li class="depth-2 branch"><a href="fastmath.complex.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>complex</span></div></a></li><li class="depth-2 branch"><a href="fastmath.core.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>core</span></div></a></li><li class="depth-2 branch"><a href="fastmath.distance.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>distance</span></div></a></li><li class="depth-2 branch"><a href="fastmath.easings.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>easings</span></div></a></li><li class="depth-2 branch"><a href="fastmath.fields.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>fields</span></div></a></li><li class="depth-2 branch"><a href="fastmath.gp.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>gp</span></div></a></li><li class="depth-2 branch"><a href="fastmath.grid.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>grid</span></div></a></li><li class="depth-2 branch"><a href="fastmath.interpolation.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>interpolation</span></div></a></li><li class="depth-2 branch"><a href="fastmath.kernel.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>kernel</span></div></a></li><li class="depth-2 branch current"><a href="fastmath.optimization.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>optimization</span></div></a></li><li class="depth-2 branch"><a href="fastmath.protocols.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>protocols</span></div></a></li><li class="depth-2 branch"><a href="fastmath.random.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>random</span></div></a></li><li class="depth-2 branch"><a href="fastmath.signal.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>signal</span></div></a></li><li class="depth-2 branch"><a href="fastmath.stats.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>stats</span></div></a></li><li class="depth-2 branch"><a href="fastmath.transform.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>transform</span></div></a></li><li class="depth-2"><a href="fastmath.vector.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>vector</span></div></a></li></ul></div><div class="sidebar secondary"><h3><a href="#top"><span class="inner">Public Vars</span></a></h3><ul><li class="depth-1"><a href="fastmath.optimization.html#var-bayesian-optimization"><div class="inner"><span>bayesian-optimization</span></div></a></li><li class="depth-1"><a href="fastmath.optimization.html#var-maximize"><div class="inner"><span>maximize</span></div></a></li><li class="depth-1"><a href="fastmath.optimization.html#var-maximizer"><div class="inner"><span>maximizer</span></div></a></li><li class="depth-1"><a href="fastmath.optimization.html#var-minimize"><div class="inner"><span>minimize</span></div></a></li><li class="depth-1"><a href="fastmath.optimization.html#var-minimizer"><div class="inner"><span>minimizer</span></div></a></li><li class="depth-1"><a href="fastmath.optimization.html#var-scan-and-maximize"><div class="inner"><span>scan-and-maximize</span></div></a></li><li class="depth-1"><a href="fastmath.optimization.html#var-scan-and-minimize"><div class="inner"><span>scan-and-minimize</span></div></a></li></ul></div><div class="namespace-docs" id="content"><h1 class="anchor" id="top">fastmath.optimization</h1><div class="doc"><div class="markdown"><p>Optimization.</p>
<p>Namespace provides various optimization methods.</p>
<ul>
  <li>Brent (1d functions)</li>
  <li>Bobyqa (2d+ functions)</li>
  <li>Powell</li>
  <li>Nelder-Mead</li>
  <li>Multidirectional simplex</li>
  <li>CMAES</li>
  <li>Gradient</li>
  <li>Bayesian Optimization (see below)</li>
</ul>
<p>All optimizers require bounds.</p>
<h2><a href="#optimizers" name="optimizers"></a>Optimizers</h2>
<p>To optimize functions call one of the following functions:</p>
<ul>
  <li><a href="fastmath.optimization.html#var-minimize">minimize</a> or <a href="fastmath.optimization.html#var-maximize">maximize</a> - to perform actual optimization</li>
  <li><a href="fastmath.optimization.html#var-scan-and-minimize">scan-and-minimize</a> or <a href="fastmath.optimization.html#var-scan-and-maximize">scan-and-maximize</a> - functions find initial point using brute force and then perform optimization paralelly for best initialization points. Brute force scan is done using jitter low discrepancy sequence generator.</li>
</ul>
<p>You can also create optimizer (function which performs optimization) by calling <a href="fastmath.optimization.html#var-minimizer">minimizer</a> or <a href="fastmath.optimization.html#var-maximizer">maximizer</a>. Optimizer accepts initial point.</p>
<p>All above accept:</p>
<ul>
  <li>one of the optimization method, ie: <code>:brent</code>, <code>:bobyqa</code>, <code>:nelder-mead</code>, <code>:multidirectional-simplex</code>, <code>:cmaes</code>, <code>:gradient</code></li>
  <li>function to optimize</li>
  <li>parameters as a map</li>
</ul>
<p>For parameters meaning refer <a href="https://commons.apache.org/proper/commons-math/javadocs/api-3.6.1/index.html?org/apache/commons/math3/optim/package-summary.html">Optim package</a></p>
<h3><a href="#common-parameters" name="common-parameters"></a>Common parameters</h3>
<ul>
  <li><code>:bounds</code> (obligatory) - search ranges for each dimensions as a seqence of [low high] pairs</li>
  <li><code>:initial</code> - initial point other then mid of the bounds as vector</li>
  <li><code>:max-evals</code> - maximum number of function evaluations</li>
  <li><code>:max-iters</code> - maximum number of algorithm interations</li>
  <li><code>:bounded?</code> - should optimizer force to keep search within bounds (some algorithms go outside desired ranges)</li>
  <li><code>:stats?</code> - return number of iterations and evaluations along with result</li>
  <li><code>:rel</code> and <code>:abs</code> - relative and absolute accepted errors</li>
</ul>
<p>For <code>scan-and-...</code> functions additionally you can provide:</p>
<ul>
  <li><code>:N</code> - number of brute force iterations</li>
  <li><code>:n</code> - fraction of N which are used as initial points to parallel optimization</li>
  <li><code>:jitter</code> - jitter factor for sequence generator (for scanning domain)</li>
</ul>
<h3><a href="#specific-parameters" name="specific-parameters"></a>Specific parameters</h3>
<ul>
  <li>BOBYQA - <code>:number-of-points</code>, <code>:initial-radius</code>, <code>:stopping-radius</code></li>
  <li>Nelder-Mead - <code>:rho</code>, <code>:khi</code>, <code>:gamma</code>, <code>:sigma</code>, <code>:side-length</code></li>
  <li>Multidirectional simples - <code>:khi</code>, <code>:gamma</code>, <code>:side-length</code></li>
  <li>CMAES - <code>:check-feasable-count</code>, <code>:diagonal-only</code>, <code>:stop-fitness</code>, <code>:active-cma?</code>, <code>:population-size</code></li>
  <li>Gradient - <code>:bracketing-range</code>, <code>:formula</code> (<code>:polak-ribiere</code> or <code>:fletcher-reeves</code>), <code>:gradient-h</code> (finite differentiation step, default: <code>0.01</code>)</li>
</ul>
<h2><a href="#bayesian-optimization" name="bayesian-optimization"></a>Bayesian Optimization</h2>
<p>Bayesian optimizer can be used for optimizing expensive to evaluate black box functions. Refer this <a href="http://krasserm.github.io/2018/03/21/bayesian-optimization/">article</a> or this <a href="https://nextjournal.com/a/LKqpdDdxiggRyHhqDG5FH?token=Ss1Qq3MzHWN8ZyEt9UC1ZZ">article</a></p></div><div class="markdown"><h4>Categories</h4><ul></ul><p>Other vars: <a href="fastmath.optimization.html#var-bayesian-optimization">bayesian-optimization</a> <a href="fastmath.optimization.html#var-maximize">maximize</a> <a href="fastmath.optimization.html#var-maximizer">maximizer</a> <a href="fastmath.optimization.html#var-minimize">minimize</a> <a href="fastmath.optimization.html#var-minimizer">minimizer</a> <a href="fastmath.optimization.html#var-scan-and-maximize">scan-and-maximize</a> <a href="fastmath.optimization.html#var-scan-and-minimize">scan-and-minimize</a></p></div></div><div class="public anchor" id="var-bayesian-optimization"><h3>bayesian-optimization</h3><div class="usage"><code>(bayesian-optimization f {:keys [warm-up init-points bounds utility-function-type utility-param kernel kscale jitter noise optimizer optimizer-params normalize?], :or {kscale 1.0, kernel (k/kernel :mattern-52), warm-up (* (count bounds) 1000), init-points 3, utility-function-type :ucb, utility-param (if (#{:ei :poi} utility-function-type) 0.001 2.576), jitter 0.25, normalize? true}})</code></div><div class="doc"><div class="markdown"><p>Bayesian optimizer</p>
<p>Parameters are:</p>
<ul>
  <li><code>:warm-up</code> - number of brute force iterations to find maximum of utility function</li>
  <li><code>:init-points</code> - number of initial evaluation before bayesian optimization starts. Points are selected using jittered low discrepancy sequence generator (see: <a href="fastmath.random.html#var-jittered-sequence-generator">jittered-sequence-generator</a></li>
  <li><code>:bounds</code> - bounds for each dimension</li>
  <li><code>:utility-function-type</code> - one of <code>:ei</code>, <code>:poi</code> or <code>:ucb</code></li>
  <li><code>:utility-param</code> - parameter for utility function (kappa for <code>ucb</code> and xi for <code>ei</code> and <code>poi</code>)</li>
  <li><code>:kernel</code> - kernel, default <code>:mattern-52</code>, see <a href="fastmath.kernel.html">fastmath.kernel</a></li>
  <li><code>:kscale</code> - scaling factor for kernel</li>
  <li><code>:jitter</code> - jitter factor for sequence generator (used to find initial points)</li>
  <li><code>:noise</code> - noise (lambda) factor for gaussian process</li>
  <li><code>:optimizer</code> - name of optimizer (used to optimized utility function)</li>
  <li><code>:optimizer-params</code> - optional parameters for optimizer</li>
  <li><code>:normalize?</code> - normalize data in gaussian process?</li>
</ul>
<p>Returns lazy sequence with consecutive executions. Each step consist:</p>
<ul>
  <li><code>:x</code> - maximum <code>x</code></li>
  <li><code>:y</code> - value</li>
  <li><code>:xs</code> - list of all visited xâ€™s</li>
  <li><code>:ys</code> - list of values for every visited x</li>
  <li><code>:gp</code> - current gaussian process regression instance</li>
  <li><code>:util-fn</code> - current utility function</li>
  <li><code>:util-best</code> - best x in utility function</li>
</ul></div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>Usage</p></blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0] [-5.0 5.0]]
      f (fn [x y]
          (+ (m/sq (+ (* x x) y -11.0)) (m/sq (+ x (* y y) -7.0))))]
  (nth (bayesian-optimization
        (fn [x y] (- (f x y)))
        {:bounds bounds, :init-points 5, :utility-function-type :poi})
       10))
;;=&gt; {:gp
;;=&gt;  #object[fastmath.gp.GaussianProcess 0x181d8dd9 "fastmath.gp.GaussianProcess@181d8dd9"],
;;=&gt;  :util-best (3.672473642678259 -1.7414785565032656),
;;=&gt;  :util-fn #<fn@2a5bf086 fastmath.optimization="" ayesian_step_fn[fn]="">,
;;=&gt;  :x (3.618512273550305 -1.9483429082248143),
;;=&gt;  :xs ((3.672473642678259 -1.7414785565032656)
;;=&gt;       (3.4582654874537546 -1.8551528957502588)
;;=&gt;       (3.6239150926043333 -1.9636563683311774)
;;=&gt;       (3.618512273550305 -1.9483429082248143)
;;=&gt;       (3.6464574719783442 -2.1165291239410933)
;;=&gt;       (3.594825930997512 -2.3045300239498143)
;;=&gt;       (3.3871289643234306 -2.275443864170927)
;;=&gt;       (3.39119683940395 -2.4735514758894706)
;;=&gt;       (3.375255421255483 -2.485727859966384)
;;=&gt;       (2.943760578705551 -2.346554991675897)
;;=&gt;       (2.6942609947243756 -2.3897724489758354)
;;=&gt;       [-1.4414366122301954 -2.7859600177642165]
;;=&gt;       [-4.811216605860162 1.424747894061765]
;;=&gt;       [2.8151479049761132 -2.370022726844256]
;;=&gt;       [0.20084918018601705 2.8023909489075196]
;;=&gt;       [-1.982161822992114 -1.1122967187327424]),
;;=&gt;  :y -0.1929623115578869,
;;=&gt;  :ys (-0.6427901873935304
;;=&gt;       -0.8120431330391881
;;=&gt;       -0.2588632283041602
;;=&gt;       -0.1929623115578869
;;=&gt;       -1.3006648741588807
;;=&gt;       -3.7773717142243606
;;=&gt;       -5.6986091903003855
;;=&gt;       -10.192414797415605
;;=&gt;       -10.905653100710543
;;=&gt;       -24.012891460741315
;;=&gt;       -39.56064526078269
;;=&gt;       -137.54464175816634
;;=&gt;       -279.88822444617597
;;=&gt;       -31.698713601355852
;;=&gt;       -67.65246281314313
;;=&gt;       -126.95128178481187)}</fn@2a5bf086></code></pre></div><div><blockquote><p>Bayesian optimization points</p></blockquote><img src="images/o/bo.jpg" /></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L435">view source</a></div></div><div class="public anchor" id="var-maximize"><h3>maximize</h3><div class="usage"><code>(maximize method f config)</code></div><div class="doc"><div class="markdown"><p>Maximize given function.</p>
<p>Parameters: optimization method, function and configuration.</p></div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>Usage</p></blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0]]
      f (fn [x]
          (+ (* 0.2 (m/sin (* 10.0 x)))
             (/ (+ 6.0 (- (* x x) (* 5.0 x))) (inc (* x x)))))]
  {:powell (maximize :powell f {:bounds bounds}),
   :brent (maximize :brent f {:bounds bounds})})
;;=&gt; {:brent [(-0.4523106823170646) 7.224689671203529],
;;=&gt;  :powell [(-0.4522927913307559) 7.224689666542709]}</code></pre></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L319">view source</a></div></div><div class="public anchor" id="var-maximizer"><h3>maximizer</h3><div class="usage"><code>(maximizer method f config)</code></div><div class="doc"><div class="markdown"><p>Create optimizer which maximizer function.</p>
<p>Returns function which performs optimization for optionally given initial point.</p></div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>Usage</p></blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0]]
      f (fn [x]
          (+ (* 0.2 (m/sin (* 10.0 x)))
             (/ (+ 6.0 (- (* x x) (* 5.0 x))) (inc (* x x)))))
      optimizer (maximizer :cmaes f {:bounds bounds})]
  {:optimizer optimizer,
   :run-1 (optimizer),
   :run-2 (optimizer [4.5]),
   :run-3 (optimizer [-4.5])})
;;=&gt; {:optimizer #<fn@525605a9 fastmath.optimization="" ptimizer[fn]="">,
;;=&gt;  :run-1 [(0.0) 6.0],
;;=&gt;  :run-2 [(-0.1759833140088034) 6.506847969857977],
;;=&gt;  :run-3 [(-0.2795930806346343) 6.866320539589353]}</fn@525605a9></code></pre></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L304">view source</a></div></div><div class="public anchor" id="var-minimize"><h3>minimize</h3><div class="usage"><code>(minimize method f config)</code></div><div class="doc"><div class="markdown"><p>Minimize given function.</p>
<p>Parameters: optimization method, function and configuration.</p></div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>1d function</p></blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0]]
      f (fn [x]
          (+ (* 0.2 (m/sin (* 10.0 x)))
             (/ (+ 6.0 (- (* x x) (* 5.0 x))) (inc (* x x)))))]
  {:powell (minimize :powell f {:bounds bounds}),
   :brent (minimize :brent f {:bounds bounds}),
   :brent-with-initial-point
   (minimize :brent f {:bounds bounds, :initial [2.0]})})
;;=&gt; {:brent [(-3.947569586073323) 2.2959519482739297],
;;=&gt;  :brent-with-initial-point [(2.979593427579756) -0.20178173314322778],
;;=&gt;  :powell [(2.3572022329682807) -0.23501046849989368]}</code></pre></div><div><blockquote><p>2d function</p></blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0] [-5.0 5.0]]
      f (fn [x y]
          (+ (m/sq (+ (* x x) y -11.0)) (m/sq (+ x (* y y) -7.0))))]
  {:bobyqa (minimize :bobyqa f {:bounds bounds}),
   :gradient (minimize :gradient f {:bounds bounds})})
;;=&gt; {:bobyqa [(3.5844283403693833 -1.848126526921083)
;;=&gt;           1.1846390625694734E-19],
;;=&gt;  :gradient [(2.999999285787787 2.0000014646814326)
;;=&gt;             3.442177688274934E-11]}</code></pre></div><div><blockquote><p>With stats</p></blockquote><pre><code class="hljs clojure">(minimize :gradient
          (fn* [p1__23394#] (m/sin p1__23394#))
          {:bounds [[-5 5]], :stats? true})
;;=&gt; {:evaluations 22, :iterations 3, :result [(-1.5707963273649799) -1.0]}</code></pre></div><div><blockquote><p>min/max of f using <code>:powell</code> optimizer</p></blockquote><img src="images/o/powell-1d.png" /></div><div><blockquote><p>min/max of f using <code>:nelder-mead</code> optimizer</p></blockquote><img src="images/o/nelder-mead-1d.png" /></div><div><blockquote><p>min/max of f using <code>:multidirectional-simplex</code> optimizer</p></blockquote><img src="images/o/multidirectional-simplex-1d.png" /></div><div><blockquote><p>min/max of f using <code>:cmaes</code> optimizer</p></blockquote><img src="images/o/cmaes-1d.png" /></div><div><blockquote><p>min/max of f using <code>:gradient</code> optimizer</p></blockquote><img src="images/o/gradient-1d.png" /></div><div><blockquote><p>min/max of f using <code>:brent</code> optimizer</p></blockquote><img src="images/o/brent-1d.png" /></div><div><blockquote><p>min/max of f using <code>:powell</code> optimizer</p></blockquote><img src="images/o/powell-2d.jpg" /></div><div><blockquote><p>min/max of f using <code>:nelder-mead</code> optimizer</p></blockquote><img src="images/o/nelder-mead-2d.jpg" /></div><div><blockquote><p>min/max of f using <code>:multidirectional-simplex</code> optimizer</p></blockquote><img src="images/o/multidirectional-simplex-2d.jpg" /></div><div><blockquote><p>min/max of f using <code>:cmaes</code> optimizer</p></blockquote><img src="images/o/cmaes-2d.jpg" /></div><div><blockquote><p>min/max of f using <code>:gradient</code> optimizer</p></blockquote><img src="images/o/gradient-2d.jpg" /></div><div><blockquote><p>min/max of f using <code>:bobyqa</code> optimizer</p></blockquote><img src="images/o/bobyqa-2d.jpg" /></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L313">view source</a></div></div><div class="public anchor" id="var-minimizer"><h3>minimizer</h3><div class="usage"><code>(minimizer method f config)</code></div><div class="doc"><div class="markdown"><p>Create optimizer which minimizes function.</p>
<p>Returns function which performs optimization for optionally given initial point.</p></div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>Usage</p></blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0]]
      f (fn [x]
          (+ (* 0.2 (m/sin (* 10.0 x)))
             (/ (+ 6.0 (- (* x x) (* 5.0 x))) (inc (* x x)))))
      optimizer (minimizer :brent f {:bounds bounds})]
  {:optimizer optimizer,
   :run-1 (optimizer),
   :run-2 (optimizer [4.5]),
   :run-3 (optimizer [-4.5])})
;;=&gt; {:optimizer #<fn@361397fb fastmath.optimization="" ptimizer[fn]="">,
;;=&gt;  :run-1 [(-3.947569586073323) 2.2959519482739297],
;;=&gt;  :run-2 [(2.357114991599655) -0.2350104692683484],
;;=&gt;  :run-3 [(-4.570514545168775) 2.074718566761628]}</fn@361397fb></code></pre></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L298">view source</a></div></div><div class="public anchor" id="var-scan-and-maximize"><h3>scan-and-maximize</h3><div class="usage"></div><div class="doc"><div class="markdown"></div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>Usage</p></blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0]]
      f (fn [x]
          (+ (* 0.2 (m/sin (* 10.0 x)))
             (/ (+ 6.0 (- (* x x) (* 5.0 x))) (inc (* x x)))))]
  {:powell (scan-and-maximize :powell f {:bounds bounds}),
   :brent (scan-and-maximize :brent f {:bounds bounds})})
;;=&gt; {:brent [(-0.45231069112541833) 7.22468967120353],
;;=&gt;  :powell [(-0.45231471458592787) 7.224689670968358]}</code></pre></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L371">view source</a></div></div><div class="public anchor" id="var-scan-and-minimize"><h3>scan-and-minimize</h3><div class="usage"></div><div class="doc"><div class="markdown"></div></div><div class="markdown"><h4>Examples</h4><div><blockquote><p>1d function</p></blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0]]
      f (fn [x]
          (+ (* 0.2 (m/sin (* 10.0 x)))
             (/ (+ 6.0 (- (* x x) (* 5.0 x))) (inc (* x x)))))]
  {:powell (scan-and-minimize :powell f {:bounds bounds}),
   :brent (scan-and-minimize :brent f {:bounds bounds})})
;;=&gt; {:brent [(2.35711490979954) -0.23501046926842528],
;;=&gt;  :powell [(2.3571208005896818) -0.23501046891486016]}</code></pre></div><div><blockquote><p>2d function</p></blockquote><pre><code class="hljs clojure">(let [bounds [[-5.0 5.0] [-5.0 5.0]]
      f (fn [x y]
          (+ (m/sq (+ (* x x) y -11.0)) (m/sq (+ x (* y y) -7.0))))]
  {:bobyqa (scan-and-minimize :bobyqa f {:bounds bounds}),
   :gradient (scan-and-minimize :gradient f {:bounds bounds})})
;;=&gt; {:bobyqa [(2.9999999999935567 2.000000000056682)
;;=&gt;           4.8850752449334874E-20],
;;=&gt;  :gradient [(3.584428354622244 -1.8481262200688962)
;;=&gt;             1.4221286796307624E-12]}</code></pre></div></div><div class="src-link"><a href="https://github.com/generateme/fastmath/blob/master/src/fastmath/optimization.clj#L370">view source</a></div></div></div></body></html>